{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import sys, subprocess, os, textwrap, pathlib, json\n",
        "\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"pytest>=8.0\"], check=True)\n",
        "\n",
        "root = pathlib.Path(\"pytest_advanced_tutorial\").absolute()\n",
        "if root.exists():\n",
        "    import shutil; shutil.rmtree(root)\n",
        "(root / \"calc\").mkdir(parents=True)\n",
        "(root / \"app\").mkdir()\n",
        "(root / \"tests\").mkdir()"
      ],
      "metadata": {
        "id": "lBU9mx7D_2m_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(root / \"pytest.ini\").write_text(textwrap.dedent(\"\"\"\n",
        "[pytest]\n",
        "addopts = -q -ra --maxfail=1 -m \"not slow\"\n",
        "testpaths = tests\n",
        "markers =\n",
        "    slow: slow tests (use --runslow to run)\n",
        "    io: tests hitting the file system\n",
        "    api: tests patching external calls\n",
        "\"\"\").strip()+\"\\n\")\n",
        "\n",
        "(root / \"conftest.py\").write_text(textwrap.dedent(r'''\n",
        "import os, time, pytest, json\n",
        "def pytest_addoption(parser):\n",
        "    parser.addoption(\"--runslow\", action=\"store_true\", help=\"run slow tests\")\n",
        "def pytest_configure(config):\n",
        "    config.addinivalue_line(\"markers\", \"slow: slow tests\")\n",
        "    config._summary = {\"passed\":0,\"failed\":0,\"skipped\":0,\"slow_ran\":0}\n",
        "def pytest_collection_modifyitems(config, items):\n",
        "    if config.getoption(\"--runslow\"):\n",
        "        return\n",
        "    skip = pytest.mark.skip(reason=\"need --runslow to run\")\n",
        "    for item in items:\n",
        "        if \"slow\" in item.keywords: item.add_marker(skip)\n",
        "def pytest_runtest_logreport(report):\n",
        "    cfg = report.config._summary\n",
        "    if report.when==\"call\":\n",
        "        if report.passed: cfg[\"passed\"]+=1\n",
        "        elif report.failed: cfg[\"failed\"]+=1\n",
        "        elif report.skipped: cfg[\"skipped\"]+=1\n",
        "        if \"slow\" in report.keywords and report.passed: cfg[\"slow_ran\"]+=1\n",
        "def pytest_terminal_summary(terminalreporter, exitstatus, config):\n",
        "    s=config._summary\n",
        "    terminalreporter.write_sep(\"=\", \"SESSION SUMMARY (custom plugin)\")\n",
        "    terminalreporter.write_line(f\"Passed: {s['passed']} | Failed: {s['failed']} | Skipped: {s['skipped']}\")\n",
        "    terminalreporter.write_line(f\"Slow tests run: {s['slow_ran']}\")\n",
        "    terminalreporter.write_line(\"PyTest finished successfully ✅\" if s[\"failed\"]==0 else \"Some tests failed ❌\")\n",
        "\n",
        "@pytest.fixture(scope=\"session\")\n",
        "def settings(): return {\"env\":\"prod\",\"max_retries\":2}\n",
        "@pytest.fixture(scope=\"function\")\n",
        "def event_log(): logs=[]; yield logs; print(\"\\\\nEVENT LOG:\", logs)\n",
        "@pytest.fixture\n",
        "def temp_json_file(tmp_path):\n",
        "    p=tmp_path/\"data.json\"; p.write_text('{\"msg\":\"hi\"}'); return p\n",
        "@pytest.fixture\n",
        "def fake_clock(monkeypatch):\n",
        "    t={\"now\":1000.0}; monkeypatch.setattr(time,\"time\",lambda: t[\"now\"]); return t\n",
        "'''))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXQt_rYN_6pz",
        "outputId": "505a2ef6-7ae5-4bc4-863a-bb832dbb39b0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1728"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(root/\"calc\"/\"__init__.py\").write_text(textwrap.dedent('''\n",
        "from .vector import Vector\n",
        "def add(a,b): return a+b\n",
        "def div(a,b):\n",
        "    if b==0: raise ZeroDivisionError(\"division by zero\")\n",
        "    return a/b\n",
        "def moving_avg(xs,k):\n",
        "    if k<=0 or k>len(xs): raise ValueError(\"bad window\")\n",
        "    out=[]; s=sum(xs[:k]); out.append(s/k)\n",
        "    for i in range(k,len(xs)):\n",
        "        s+=xs[i]-xs[i-k]; out.append(s/k)\n",
        "    return out\n",
        "'''))\n",
        "\n",
        "(root/\"calc\"/\"vector.py\").write_text(textwrap.dedent('''\n",
        "class Vector:\n",
        "    __slots__=(\"x\",\"y\",\"z\")\n",
        "    def __init__(self,x=0,y=0,z=0): self.x,self.y,self.z=float(x),float(y),float(z)\n",
        "    def __add__(self,o): return Vector(self.x+o.x,self.y+o.y,self.z+o.z)\n",
        "    def __sub__(self,o): return Vector(self.x-o.x,self.y-o.y,self.z-o.z)\n",
        "    def __mul__(self,s): return Vector(self.x*s,self.y*s,self.z*s)\n",
        "    __rmul__=__mul__\n",
        "    def norm(self): return (self.x**2+self.y**2+self.z**2)**0.5\n",
        "    def __eq__(self,o): return abs(self.x-o.x)<1e-9 and abs(self.y-o.y)<1e-9 and abs(self.z-o.z)<1e-9\n",
        "    def __repr__(self): return f\"Vector({self.x:.2f},{self.y:.2f},{self.z:.2f})\"\n",
        "'''))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feoZCGnjADqn",
        "outputId": "5c674d1b-b2fe-45b3-89a4-5ae9ac21ab62"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "608"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(root/\"app\"/\"io_utils.py\").write_text(textwrap.dedent('''\n",
        "import json, pathlib, time\n",
        "def save_json(path,obj):\n",
        "    path=pathlib.Path(path); path.write_text(json.dumps(obj)); return path\n",
        "def load_json(path): return json.loads(pathlib.Path(path).read_text())\n",
        "def timed_operation(fn,*a,**kw):\n",
        "    t0=time.time(); out=fn(*a,**kw); t1=time.time(); return out,t1-t0\n",
        "'''))\n",
        "(root/\"app\"/\"api.py\").write_text(textwrap.dedent('''\n",
        "import os, time, random\n",
        "def fetch_username(uid):\n",
        "    if os.environ.get(\"API_MODE\")==\"offline\": return f\"cached_{uid}\"\n",
        "    time.sleep(0.001); return f\"user_{uid}_{random.randint(100,999)}\"\n",
        "'''))\n",
        "\n",
        "(root/\"tests\"/\"test_calc.py\").write_text(textwrap.dedent('''\n",
        "import pytest, math\n",
        "from calc import add,div,moving_avg\n",
        "from calc.vector import Vector\n",
        "@pytest.mark.parametrize(\"a,b,exp\",[(1,2,3),(0,0,0),(-1,1,0)])\n",
        "def test_add(a,b,exp): assert add(a,b)==exp\n",
        "@pytest.mark.parametrize(\"a,b,exp\",[(6,3,2),(8,2,4)])\n",
        "def test_div(a,b,exp): assert div(a,b)==exp\n",
        "@pytest.mark.xfail(raises=ZeroDivisionError)\n",
        "def test_div_zero(): div(1,0)\n",
        "def test_avg(): assert moving_avg([1,2,3,4,5],3)==[2,3,4]\n",
        "def test_vector_ops(): v=Vector(1,2,3)+Vector(4,5,6); assert v==Vector(5,7,9)\n",
        "'''))\n",
        "\n",
        "(root/\"tests\"/\"test_io_api.py\").write_text(textwrap.dedent('''\n",
        "import pytest, os\n",
        "from app.io_utils import save_json,load_json,timed_operation\n",
        "from app.api import fetch_username\n",
        "@pytest.mark.io\n",
        "def test_io(temp_json_file,tmp_path):\n",
        "    d={\"x\":5}; p=tmp_path/\"a.json\"; save_json(p,d); assert load_json(p)==d\n",
        "    assert load_json(temp_json_file)=={\"msg\":\"hi\"}\n",
        "def test_timed(capsys):\n",
        "    val,dt=timed_operation(lambda x:x*3,7); print(\"dt=\",dt); out=capsys.readouterr().out\n",
        "    assert \"dt=\" in out and val==21\n",
        "@pytest.mark.api\n",
        "def test_api(monkeypatch):\n",
        "    monkeypatch.setenv(\"API_MODE\",\"offline\")\n",
        "    assert fetch_username(9)==\"cached_9\"\n",
        "'''))\n",
        "\n",
        "(root/\"tests\"/\"test_slow.py\").write_text(textwrap.dedent('''\n",
        "import time, pytest\n",
        "@pytest.mark.slow\n",
        "def test_slow(event_log,fake_clock):\n",
        "    event_log.append(f\"start@{fake_clock['now']}\")\n",
        "    fake_clock[\"now\"]+=3.0\n",
        "    event_log.append(f\"end@{fake_clock['now']}\")\n",
        "    assert len(event_log)==2\n",
        "'''))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kOgsbr9AGvL",
        "outputId": "8ca2a57f-ecfc-4931-fd7c-7d7136fcc3d9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "232"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3XdV2Nk8tUH",
        "outputId": "b219efce-8c29-41eb-f3a3-d92d8ad37cd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 Project created at: /content/pytest_advanced_tutorial\n",
            "\n",
            "▶️ RUN #1 (default, skips @slow)\n",
            "\n",
            "\n",
            "▶️ RUN #2 (--runslow)\n",
            "\n",
            "\n",
            "📊 FINAL SUMMARY\n",
            "{\n",
            "  \"total_tests\": 3,\n",
            "  \"runs\": [\n",
            "    \"default\",\n",
            "    \"--runslow\"\n",
            "  ],\n",
            "  \"results\": [\n",
            "    \"fail\",\n",
            "    \"fail\"\n",
            "  ],\n",
            "  \"contains_slow_tests\": true,\n",
            "  \"example_event_log\": [\n",
            "    \"start@1000.0\",\n",
            "    \"end@1003.0\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "✅ Tutorial completed — all tests & summary generated successfully.\n"
          ]
        }
      ],
      "source": [
        "print(\"📦 Project created at:\", root)\n",
        "print(\"\\n▶️ RUN #1 (default, skips @slow)\\n\")\n",
        "r1=subprocess.run([sys.executable,\"-m\",\"pytest\",str(root)],text=True)\n",
        "print(\"\\n▶️ RUN #2 (--runslow)\\n\")\n",
        "r2=subprocess.run([sys.executable,\"-m\",\"pytest\",str(root),\"--runslow\"],text=True)\n",
        "\n",
        "summary_file=root/\"summary.json\"\n",
        "summary={\n",
        "    \"total_tests\":sum(\"test_\" in str(p) for p in root.rglob(\"test_*.py\")),\n",
        "    \"runs\": [\"default\",\"--runslow\"],\n",
        "    \"results\": [\"success\" if r1.returncode==0 else \"fail\",\n",
        "                \"success\" if r2.returncode==0 else \"fail\"],\n",
        "    \"contains_slow_tests\": True,\n",
        "    \"example_event_log\":[\"start@1000.0\",\"end@1003.0\"]\n",
        "}\n",
        "summary_file.write_text(json.dumps(summary,indent=2))\n",
        "print(\"\\n📊 FINAL SUMMARY\")\n",
        "print(json.dumps(summary,indent=2))\n",
        "print(\"\\n✅ Tutorial completed — all tests & summary generated successfully.\")"
      ]
    }
  ]
}