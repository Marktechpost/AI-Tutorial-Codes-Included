{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.26.4\n",
        "!pip install -q lightly torch torchvision matplotlib scikit-learn umap-learn\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import umap\n",
        "\n",
        "from lightly.loss import NTXentLoss\n",
        "from lightly.models.modules import SimCLRProjectionHead\n",
        "from lightly.transforms import SimCLRTransform\n",
        "from lightly.data import LightlyDataset\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")"
      ],
      "metadata": {
        "id": "F3i00_qnlD6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimCLRModel(nn.Module):\n",
        "    \"\"\"SimCLR model with ResNet backbone\"\"\"\n",
        "    def __init__(self, backbone, hidden_dim=512, out_dim=128):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.backbone.fc = nn.Identity()\n",
        "        self.projection_head = SimCLRProjectionHead(\n",
        "            input_dim=512, hidden_dim=hidden_dim, output_dim=out_dim\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.backbone(x).flatten(start_dim=1)\n",
        "        z = self.projection_head(features)\n",
        "        return z\n",
        "\n",
        "    def extract_features(self, x):\n",
        "        \"\"\"Extract backbone features without projection\"\"\"\n",
        "        with torch.no_grad():\n",
        "            return self.backbone(x).flatten(start_dim=1)"
      ],
      "metadata": {
        "id": "dwLxx0OTlGUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(train=True):\n",
        "    \"\"\"Load CIFAR-10 dataset\"\"\"\n",
        "    ssl_transform = SimCLRTransform(input_size=32, cj_prob=0.8)\n",
        "\n",
        "    eval_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "    ])\n",
        "\n",
        "    base_dataset = torchvision.datasets.CIFAR10(\n",
        "        root='./data', train=train, download=True\n",
        "    )\n",
        "\n",
        "    class SSLDataset(torch.utils.data.Dataset):\n",
        "        def __init__(self, dataset, transform):\n",
        "            self.dataset = dataset\n",
        "            self.transform = transform\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.dataset)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            img, label = self.dataset[idx]\n",
        "            return self.transform(img), label\n",
        "\n",
        "    ssl_dataset = SSLDataset(base_dataset, ssl_transform)\n",
        "\n",
        "    eval_dataset = torchvision.datasets.CIFAR10(\n",
        "        root='./data', train=train, download=True, transform=eval_transform\n",
        "    )\n",
        "\n",
        "    return ssl_dataset, eval_dataset"
      ],
      "metadata": {
        "id": "Ji8KLNrnlJbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_ssl_model(model, dataloader, epochs=5, device='cuda'):\n",
        "    \"\"\"Train SimCLR model\"\"\"\n",
        "    model.to(device)\n",
        "    criterion = NTXentLoss(temperature=0.5)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.06, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "    print(\"\\n=== Self-Supervised Training ===\")\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for batch_idx, batch in enumerate(dataloader):\n",
        "            views = batch[0]\n",
        "            view1, view2 = views[0].to(device), views[1].to(device)\n",
        "\n",
        "            z1 = model(view1)\n",
        "            z2 = model(view2)\n",
        "            loss = criterion(z1, z2)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            if batch_idx % 50 == 0:\n",
        "                print(f\"Epoch {epoch+1}/{epochs} | Batch {batch_idx} | Loss: {loss.item():.4f}\")\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        print(f\"Epoch {epoch+1} Complete | Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "jzGX4mGClPul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_embeddings(model, dataset, device='cuda', batch_size=256):\n",
        "    \"\"\"Generate embeddings for the entire dataset\"\"\"\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    embeddings = []\n",
        "    labels = []\n",
        "\n",
        "    print(\"\\n=== Generating Embeddings ===\")\n",
        "    with torch.no_grad():\n",
        "        for images, targets in dataloader:\n",
        "            images = images.to(device)\n",
        "            features = model.extract_features(images)\n",
        "            embeddings.append(features.cpu().numpy())\n",
        "            labels.append(targets.numpy())\n",
        "\n",
        "    embeddings = np.vstack(embeddings)\n",
        "    labels = np.concatenate(labels)\n",
        "\n",
        "    print(f\"Generated {embeddings.shape[0]} embeddings with dimension {embeddings.shape[1]}\")\n",
        "    return embeddings, labels\n",
        "\n",
        "def visualize_embeddings(embeddings, labels, method='umap', n_samples=5000):\n",
        "    \"\"\"Visualize embeddings using UMAP or t-SNE\"\"\"\n",
        "    print(f\"\\n=== Visualizing Embeddings with {method.upper()} ===\")\n",
        "\n",
        "    if len(embeddings) > n_samples:\n",
        "        indices = np.random.choice(len(embeddings), n_samples, replace=False)\n",
        "        embeddings = embeddings[indices]\n",
        "        labels = labels[indices]\n",
        "\n",
        "    if method == 'umap':\n",
        "        reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, metric='cosine')\n",
        "    else:\n",
        "        reducer = TSNE(n_components=2, perplexity=30, metric='cosine')\n",
        "\n",
        "    embeddings_2d = reducer.fit_transform(embeddings)\n",
        "\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1],\n",
        "                          c=labels, cmap='tab10', s=5, alpha=0.6)\n",
        "    plt.colorbar(scatter)\n",
        "    plt.title(f'CIFAR-10 Embeddings ({method.upper()})')\n",
        "    plt.xlabel('Component 1')\n",
        "    plt.ylabel('Component 2')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'embeddings_{method}.png', dpi=150)\n",
        "    print(f\"Saved visualization to embeddings_{method}.png\")\n",
        "    plt.show()\n",
        "\n",
        "def select_coreset(embeddings, labels, budget=1000, method='diversity'):\n",
        "    \"\"\"\n",
        "    Select a coreset using different strategies:\n",
        "    - diversity: Maximum diversity using k-center greedy\n",
        "    - balanced: Class-balanced selection\n",
        "    \"\"\"\n",
        "    print(f\"\\n=== Coreset Selection ({method}) ===\")\n",
        "\n",
        "    if method == 'balanced':\n",
        "        selected_indices = []\n",
        "        n_classes = len(np.unique(labels))\n",
        "        per_class = budget // n_classes\n",
        "\n",
        "        for cls in range(n_classes):\n",
        "            cls_indices = np.where(labels == cls)[0]\n",
        "            selected = np.random.choice(cls_indices, min(per_class, len(cls_indices)), replace=False)\n",
        "            selected_indices.extend(selected)\n",
        "\n",
        "        return np.array(selected_indices)\n",
        "\n",
        "    elif method == 'diversity':\n",
        "        selected_indices = []\n",
        "        remaining_indices = set(range(len(embeddings)))\n",
        "\n",
        "        first_idx = np.random.randint(len(embeddings))\n",
        "        selected_indices.append(first_idx)\n",
        "        remaining_indices.remove(first_idx)\n",
        "\n",
        "        for _ in range(budget - 1):\n",
        "            if not remaining_indices:\n",
        "                break\n",
        "\n",
        "            remaining = list(remaining_indices)\n",
        "            selected_emb = embeddings[selected_indices]\n",
        "            remaining_emb = embeddings[remaining]\n",
        "\n",
        "            distances = np.min(\n",
        "                np.linalg.norm(remaining_emb[:, None] - selected_emb, axis=2), axis=1\n",
        "            )\n",
        "\n",
        "            max_dist_idx = np.argmax(distances)\n",
        "            selected_idx = remaining[max_dist_idx]\n",
        "            selected_indices.append(selected_idx)\n",
        "            remaining_indices.remove(selected_idx)\n",
        "\n",
        "        print(f\"Selected {len(selected_indices)} samples\")\n",
        "        return np.array(selected_indices)"
      ],
      "metadata": {
        "id": "uWFXCXUmlUsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_linear_probe(model, train_subset, test_dataset, device='cuda'):\n",
        "    \"\"\"Train linear classifier on frozen features\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    train_loader = DataLoader(train_subset, batch_size=128, shuffle=True, num_workers=2)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=2)\n",
        "\n",
        "    classifier = nn.Linear(512, 10).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(10):\n",
        "        classifier.train()\n",
        "        for images, targets in train_loader:\n",
        "            images, targets = images.to(device), targets.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                features = model.extract_features(images)\n",
        "\n",
        "            outputs = classifier(features)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    classifier.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in test_loader:\n",
        "            images, targets = images.to(device), targets.to(device)\n",
        "            features = model.extract_features(images)\n",
        "            outputs = classifier(features)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    accuracy = 100. * correct / total\n",
        "    return accuracy\n",
        "\n",
        "def main():\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    ssl_dataset, eval_dataset = load_dataset(train=True)\n",
        "    _, test_dataset = load_dataset(train=False)\n",
        "\n",
        "    ssl_subset = Subset(ssl_dataset, range(10000))\n",
        "    ssl_loader = DataLoader(ssl_subset, batch_size=128, shuffle=True, num_workers=2, drop_last=True)\n",
        "\n",
        "    backbone = torchvision.models.resnet18(pretrained=False)\n",
        "    model = SimCLRModel(backbone)\n",
        "    model = train_ssl_model(model, ssl_loader, epochs=5, device=device)\n",
        "\n",
        "    eval_subset = Subset(eval_dataset, range(10000))\n",
        "    embeddings, labels = generate_embeddings(model, eval_subset, device=device)\n",
        "\n",
        "    visualize_embeddings(embeddings, labels, method='umap')\n",
        "\n",
        "    coreset_indices = select_coreset(embeddings, labels, budget=1000, method='diversity')\n",
        "    coreset_subset = Subset(eval_dataset, coreset_indices)\n",
        "\n",
        "    print(\"\\n=== Active Learning Evaluation ===\")\n",
        "    coreset_acc = evaluate_linear_probe(model, coreset_subset, test_dataset, device=device)\n",
        "    print(f\"Coreset Accuracy (1000 samples): {coreset_acc:.2f}%\")\n",
        "\n",
        "    random_indices = np.random.choice(len(eval_subset), 1000, replace=False)\n",
        "    random_subset = Subset(eval_dataset, random_indices)\n",
        "    random_acc = evaluate_linear_probe(model, random_subset, test_dataset, device=device)\n",
        "    print(f\"Random Accuracy (1000 samples): {random_acc:.2f}%\")\n",
        "\n",
        "    print(f\"\\nCoreset improvement: +{coreset_acc - random_acc:.2f}%\")\n",
        "\n",
        "    print(\"\\n=== Tutorial Complete! ===\")\n",
        "    print(\"Key takeaways:\")\n",
        "    print(\"1. Self-supervised learning creates meaningful representations without labels\")\n",
        "    print(\"2. Embeddings capture semantic similarity between images\")\n",
        "    print(\"3. Smart data selection (coreset) outperforms random sampling\")\n",
        "    print(\"4. Active learning reduces labeling costs while maintaining accuracy\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "tJVYwEojiZgJ",
        "outputId": "fd92711f-dfcd-481a-bccf-b6ef8227b40a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Collecting numpy==1.26.4\n",
            "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "Installing collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "1cdd43f7973444e588dd5def60d710cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: False\n",
            "Using device: cpu\n",
            "\n",
            "=== Self-Supervised Training ===\n",
            "Epoch 1/5 | Batch 0 | Loss: 5.5125\n",
            "Epoch 1/5 | Batch 50 | Loss: 5.2254\n"
          ]
        }
      ]
    }
  ]
}