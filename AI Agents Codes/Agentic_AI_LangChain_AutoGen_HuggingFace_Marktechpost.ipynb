{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from typing import List, Dict\n",
        "import autogen\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_community.llms import HuggingFacePipeline\n",
        "from transformers import pipeline\n",
        "import json\n",
        "\n",
        "print(\"üöÄ Loading models...\\n\")\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text2text-generation\",\n",
        "    model=\"google/flan-t5-base\",\n",
        "    max_length=200,\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=pipe)\n",
        "print(\"‚úì Models loaded!\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFNaud8oqKlE",
        "outputId": "df72f613-a26d-4454-caf7-b7f1a5ed5db1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Loading models...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Models loaded!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def demo_langchain_basics():\n",
        "    print(\"=\"*70)\n",
        "    print(\"DEMO 1: LangChain - Intelligent Prompt Chains\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"task\"],\n",
        "        template=\"Task: {task}\\n\\nProvide a detailed step-by-step solution:\"\n",
        "    )\n",
        "    chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    task = \"Create a Python function to calculate fibonacci sequence\"\n",
        "    print(f\"Task: {task}\\n\")\n",
        "    result = chain.run(task=task)\n",
        "    print(f\"LangChain Response:\\n{result}\\n\")\n",
        "    print(\"‚úì LangChain demo complete\\n\")\n",
        "\n",
        "def demo_langchain_multi_step():\n",
        "    print(\"=\"*70)\n",
        "    print(\"DEMO 2: LangChain - Multi-Step Reasoning\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "    planner = PromptTemplate(\n",
        "        input_variables=[\"goal\"],\n",
        "        template=\"Break down this goal into 3 steps: {goal}\"\n",
        "    )\n",
        "    executor = PromptTemplate(\n",
        "        input_variables=[\"step\"],\n",
        "        template=\"Explain how to execute this step: {step}\"\n",
        "    )\n",
        "    plan_chain = LLMChain(llm=llm, prompt=planner)\n",
        "    exec_chain = LLMChain(llm=llm, prompt=executor)\n",
        "    goal = \"Build a machine learning model\"\n",
        "    print(f\"Goal: {goal}\\n\")\n",
        "    plan = plan_chain.run(goal=goal)\n",
        "    print(f\"Plan:\\n{plan}\\n\")\n",
        "    print(\"Executing first step...\")\n",
        "    execution = exec_chain.run(step=\"Collect and prepare data\")\n",
        "    print(f\"Execution:\\n{execution}\\n\")\n",
        "    print(\"‚úì Multi-step reasoning complete\\n\")"
      ],
      "metadata": {
        "id": "pE8LwmqiqKaG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleAgent:\n",
        "    def __init__(self, name: str, role: str, llm_pipeline):\n",
        "        self.name = name\n",
        "        self.role = role\n",
        "        self.pipe = llm_pipeline\n",
        "        self.memory = []\n",
        "    def process(self, message: str) -> str:\n",
        "        prompt = f\"You are a {self.role}.\\nUser: {message}\\nYour response:\"\n",
        "        response = self.pipe(prompt, max_length=150)[0]['generated_text']\n",
        "        self.memory.append({\"user\": message, \"agent\": response})\n",
        "        return response\n",
        "    def __repr__(self):\n",
        "        return f\"Agent({self.name}, role={self.role})\"\n",
        "\n",
        "def demo_simple_agents():\n",
        "    print(\"=\"*70)\n",
        "    print(\"DEMO 3: Simple Multi-Agent System\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "    researcher = SimpleAgent(\"Researcher\", \"research specialist\", pipe)\n",
        "    coder = SimpleAgent(\"Coder\", \"Python developer\", pipe)\n",
        "    reviewer = SimpleAgent(\"Reviewer\", \"code reviewer\", pipe)\n",
        "    print(\"Agents created:\", researcher, coder, reviewer, \"\\n\")\n",
        "    task = \"Create a function to sort a list\"\n",
        "    print(f\"Task: {task}\\n\")\n",
        "    print(f\"[{researcher.name}] Researching...\")\n",
        "    research = researcher.process(f\"What's the best approach to: {task}\")\n",
        "    print(f\"Research: {research[:100]}...\\n\")\n",
        "    print(f\"[{coder.name}] Coding...\")\n",
        "    code = coder.process(f\"Write Python code to: {task}\")\n",
        "    print(f\"Code: {code[:100]}...\\n\")\n",
        "    print(f\"[{reviewer.name}] Reviewing...\")\n",
        "    review = reviewer.process(f\"Review this approach: {code[:50]}\")\n",
        "    print(f\"Review: {review[:100]}...\\n\")\n",
        "    print(\"‚úì Multi-agent workflow complete\\n\")"
      ],
      "metadata": {
        "id": "kKl9wGlKqKVa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def demo_autogen_conceptual():\n",
        "    print(\"=\"*70)\n",
        "    print(\"DEMO 4: AutoGen Concepts (Conceptual Demo)\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "    agent_config = {\n",
        "        \"agents\": [\n",
        "            {\"name\": \"UserProxy\", \"type\": \"user_proxy\", \"role\": \"Coordinates tasks\"},\n",
        "            {\"name\": \"Assistant\", \"type\": \"assistant\", \"role\": \"Solves problems\"},\n",
        "            {\"name\": \"Executor\", \"type\": \"executor\", \"role\": \"Runs code\"}\n",
        "        ],\n",
        "        \"workflow\": [\n",
        "            \"1. UserProxy receives task\",\n",
        "            \"2. Assistant generates solution\",\n",
        "            \"3. Executor tests solution\",\n",
        "            \"4. Feedback loop until complete\"\n",
        "        ]\n",
        "    }\n",
        "    print(json.dumps(agent_config, indent=2))\n",
        "    print(\"\\nüìù AutoGen Key Features:\")\n",
        "    print(\"  ‚Ä¢ Automated agent chat conversations\")\n",
        "    print(\"  ‚Ä¢ Code execution capabilities\")\n",
        "    print(\"  ‚Ä¢ Human-in-the-loop support\")\n",
        "    print(\"  ‚Ä¢ Multi-agent collaboration\")\n",
        "    print(\"  ‚Ä¢ Tool/function calling\\n\")\n",
        "    print(\"‚úì AutoGen concepts explained\\n\")\n",
        "\n",
        "class MockLLM:\n",
        "    def __init__(self):\n",
        "        self.responses = {\n",
        "            \"code\": \"def fibonacci(n):\\n    if n <= 1:\\n        return n\\n    return fibonacci(n-1) + fibonacci(n-2)\",\n",
        "            \"explain\": \"This is a recursive implementation of the Fibonacci sequence.\",\n",
        "            \"review\": \"The code is correct but could be optimized with memoization.\",\n",
        "            \"default\": \"I understand. Let me help with that task.\"\n",
        "        }\n",
        "    def generate(self, prompt: str) -> str:\n",
        "        prompt_lower = prompt.lower()\n",
        "        if \"code\" in prompt_lower or \"function\" in prompt_lower:\n",
        "            return self.responses[\"code\"]\n",
        "        elif \"explain\" in prompt_lower:\n",
        "            return self.responses[\"explain\"]\n",
        "        elif \"review\" in prompt_lower:\n",
        "            return self.responses[\"review\"]\n",
        "        return self.responses[\"default\"]\n",
        "\n",
        "def demo_autogen_with_mock():\n",
        "    print(\"=\"*70)\n",
        "    print(\"DEMO 5: AutoGen with Custom LLM Backend\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "    mock_llm = MockLLM()\n",
        "    conversation = [\n",
        "        (\"User\", \"Create a fibonacci function\"),\n",
        "        (\"CodeAgent\", mock_llm.generate(\"write code for fibonacci\")),\n",
        "        (\"ReviewAgent\", mock_llm.generate(\"review this code\")),\n",
        "    ]\n",
        "    print(\"Simulated AutoGen Multi-Agent Conversation:\\n\")\n",
        "    for speaker, message in conversation:\n",
        "        print(f\"[{speaker}]\")\n",
        "        print(f\"{message}\\n\")\n",
        "    print(\"‚úì AutoGen simulation complete\\n\")"
      ],
      "metadata": {
        "id": "7Nd5g1e6qKSY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def demo_hybrid_system():\n",
        "    print(\"=\"*70)\n",
        "    print(\"DEMO 6: Hybrid LangChain + Multi-Agent System\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "    reasoning_prompt = PromptTemplate(\n",
        "        input_variables=[\"problem\"],\n",
        "        template=\"Analyze this problem: {problem}\\nWhat are the key steps?\"\n",
        "    )\n",
        "    reasoning_chain = LLMChain(llm=llm, prompt=reasoning_prompt)\n",
        "    planner = SimpleAgent(\"Planner\", \"strategic planner\", pipe)\n",
        "    executor = SimpleAgent(\"Executor\", \"task executor\", pipe)\n",
        "    problem = \"Optimize a slow database query\"\n",
        "    print(f\"Problem: {problem}\\n\")\n",
        "    print(\"[LangChain] Analyzing problem...\")\n",
        "    analysis = reasoning_chain.run(problem=problem)\n",
        "    print(f\"Analysis: {analysis[:120]}...\\n\")\n",
        "    print(f\"[{planner.name}] Creating plan...\")\n",
        "    plan = planner.process(f\"Plan how to: {problem}\")\n",
        "    print(f\"Plan: {plan[:120]}...\\n\")\n",
        "    print(f\"[{executor.name}] Executing...\")\n",
        "    result = executor.process(f\"Execute: Add database indexes\")\n",
        "    print(f\"Result: {result[:120]}...\\n\")\n",
        "    print(\"‚úì Hybrid system complete\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\"*70)\n",
        "    print(\"ü§ñ ADVANCED AGENTIC AI TUTORIAL\")\n",
        "    print(\"AutoGen + LangChain + HuggingFace\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "    demo_langchain_basics()\n",
        "    demo_langchain_multi_step()\n",
        "    demo_simple_agents()\n",
        "    demo_autogen_conceptual()\n",
        "    demo_autogen_with_mock()\n",
        "    demo_hybrid_system()\n",
        "    print(\"=\"*70)\n",
        "    print(\"üéâ TUTORIAL COMPLETE!\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nüìö What You Learned:\")\n",
        "    print(\"  ‚úì LangChain prompt engineering and chains\")\n",
        "    print(\"  ‚úì Multi-step reasoning with LangChain\")\n",
        "    print(\"  ‚úì Building custom multi-agent systems\")\n",
        "    print(\"  ‚úì AutoGen architecture and concepts\")\n",
        "    print(\"  ‚úì Combining LangChain + agents\")\n",
        "    print(\"  ‚úì Using HuggingFace models (no API needed!)\")\n",
        "    print(\"\\nüí° Key Takeaway:\")\n",
        "    print(\"  You can build powerful agentic AI systems without expensive APIs!\")\n",
        "    print(\"  Combine LangChain's chains with multi-agent architectures for\")\n",
        "    print(\"  intelligent, autonomous AI systems.\")\n",
        "    print(\"=\"*70 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sR1_2URIqKLi",
        "outputId": "0b1c5313-dc57-48e6-a26b-0cf68e38e7b9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "ü§ñ ADVANCED AGENTIC AI TUTORIAL\n",
            "AutoGen + LangChain + HuggingFace\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "DEMO 1: LangChain - Intelligent Prompt Chains\n",
            "======================================================================\n",
            "\n",
            "Task: Create a Python function to calculate fibonacci sequence\n",
            "\n",
            "LangChain Response:\n",
            "A fibonacci sequence is a fibonacci sequence. A fibonacci sequence is a fibonacci sequence. A fibonacci sequence is a fibonacci sequence. The fibonacci sequence is a fibonacci sequence. The fibonacci sequence is a fibonacci sequence. The fibonacci sequence is a fibonacci sequence. The fibonacci sequence is a fibonacci sequence. The fibonacci sequence is a fibonacci sequence. The fibonacci sequence is a fibonacci sequence. The fibonacci sequence is a fibonacci sequence. The fibonacci sequence is a fibonacci sequence. The fibonacci sequence is a fibonacci sequence. The fibonacci sequence is a fibonacci sequence. The fibona\n",
            "\n",
            "‚úì LangChain demo complete\n",
            "\n",
            "======================================================================\n",
            "DEMO 2: LangChain - Multi-Step Reasoning\n",
            "======================================================================\n",
            "\n",
            "Goal: Build a machine learning model\n",
            "\n",
            "Plan:\n",
            "Step1: Build a machine learning model. Step2: Build a machine learning model.\n",
            "\n",
            "Executing first step...\n",
            "Execution:\n",
            "Collect and prepare data.\n",
            "\n",
            "‚úì Multi-step reasoning complete\n",
            "\n",
            "======================================================================\n",
            "DEMO 3: Simple Multi-Agent System\n",
            "======================================================================\n",
            "\n",
            "Agents created: Agent(Researcher, role=research specialist) Agent(Coder, role=Python developer) Agent(Reviewer, role=code reviewer) \n",
            "\n",
            "Task: Create a function to sort a list\n",
            "\n",
            "[Researcher] Researching...\n",
            "Research: To sort a list of items, click on the item you want to sort and then click on the item you want to s...\n",
            "\n",
            "[Coder] Coding...\n",
            "Code: a=list(map(int,input().split())) b=list(map(int,input().split())) c=list(map(int,input().split())) d...\n",
            "\n",
            "[Reviewer] Reviewing...\n",
            "Review: a=list(map(int,input().split())))...\n",
            "\n",
            "‚úì Multi-agent workflow complete\n",
            "\n",
            "======================================================================\n",
            "DEMO 4: AutoGen Concepts (Conceptual Demo)\n",
            "======================================================================\n",
            "\n",
            "{\n",
            "  \"agents\": [\n",
            "    {\n",
            "      \"name\": \"UserProxy\",\n",
            "      \"type\": \"user_proxy\",\n",
            "      \"role\": \"Coordinates tasks\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Assistant\",\n",
            "      \"type\": \"assistant\",\n",
            "      \"role\": \"Solves problems\"\n",
            "    },\n",
            "    {\n",
            "      \"name\": \"Executor\",\n",
            "      \"type\": \"executor\",\n",
            "      \"role\": \"Runs code\"\n",
            "    }\n",
            "  ],\n",
            "  \"workflow\": [\n",
            "    \"1. UserProxy receives task\",\n",
            "    \"2. Assistant generates solution\",\n",
            "    \"3. Executor tests solution\",\n",
            "    \"4. Feedback loop until complete\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "üìù AutoGen Key Features:\n",
            "  ‚Ä¢ Automated agent chat conversations\n",
            "  ‚Ä¢ Code execution capabilities\n",
            "  ‚Ä¢ Human-in-the-loop support\n",
            "  ‚Ä¢ Multi-agent collaboration\n",
            "  ‚Ä¢ Tool/function calling\n",
            "\n",
            "‚úì AutoGen concepts explained\n",
            "\n",
            "======================================================================\n",
            "DEMO 5: AutoGen with Custom LLM Backend\n",
            "======================================================================\n",
            "\n",
            "Simulated AutoGen Multi-Agent Conversation:\n",
            "\n",
            "[User]\n",
            "Create a fibonacci function\n",
            "\n",
            "[CodeAgent]\n",
            "def fibonacci(n):\n",
            "    if n <= 1:\n",
            "        return n\n",
            "    return fibonacci(n-1) + fibonacci(n-2)\n",
            "\n",
            "[ReviewAgent]\n",
            "def fibonacci(n):\n",
            "    if n <= 1:\n",
            "        return n\n",
            "    return fibonacci(n-1) + fibonacci(n-2)\n",
            "\n",
            "‚úì AutoGen simulation complete\n",
            "\n",
            "======================================================================\n",
            "DEMO 6: Hybrid LangChain + Multi-Agent System\n",
            "======================================================================\n",
            "\n",
            "Problem: Optimize a slow database query\n",
            "\n",
            "[LangChain] Analyzing problem...\n",
            "Analysis: The first step is to optimize the database query. The second step is to optimize the database query. The third step is t...\n",
            "\n",
            "[Planner] Creating plan...\n",
            "Plan: Optimize a slow database query...\n",
            "\n",
            "[Executor] Executing...\n",
            "Result: Add database indexes...\n",
            "\n",
            "‚úì Hybrid system complete\n",
            "\n",
            "======================================================================\n",
            "üéâ TUTORIAL COMPLETE!\n",
            "======================================================================\n",
            "\n",
            "üìö What You Learned:\n",
            "  ‚úì LangChain prompt engineering and chains\n",
            "  ‚úì Multi-step reasoning with LangChain\n",
            "  ‚úì Building custom multi-agent systems\n",
            "  ‚úì AutoGen architecture and concepts\n",
            "  ‚úì Combining LangChain + agents\n",
            "  ‚úì Using HuggingFace models (no API needed!)\n",
            "\n",
            "üí° Key Takeaway:\n",
            "  You can build powerful agentic AI systems without expensive APIs!\n",
            "  Combine LangChain's chains with multi-agent architectures for\n",
            "  intelligent, autonomous AI systems.\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ]
    }
  ]
}