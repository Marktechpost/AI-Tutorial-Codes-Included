{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os, re, sys, math, random, json, textwrap, subprocess, shutil, time\n",
        "from typing import List, Dict, Tuple\n",
        "try:\n",
        "    import transformers\n",
        "except:\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"transformers\", \"accelerate\", \"sentencepiece\"], check=True)\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "MODEL_NAME = os.environ.get(\"CF_MODEL\", \"google/flan-t5-small\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
        "llm = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, device_map=\"auto\")\n",
        "def llm_gen(prompt: str, max_new_tokens=160, temperature=0.0) -> str:\n",
        "    out = llm(prompt, max_new_tokens=max_new_tokens, do_sample=temperature>0.0, temperature=temperature)[0][\"generated_text\"]\n",
        "    return out.strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e7PBMlWvWh0",
        "outputId": "4b7b78bb-412b-4705-ca9e-da0fa75551bc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast, operator as op\n",
        "OPS = {ast.Add: op.add, ast.Sub: op.sub, ast.Mult: op.mul, ast.Div: op.truediv, ast.Pow: op.pow, ast.USub: op.neg, ast.FloorDiv: op.floordiv, ast.Mod: op.mod}\n",
        "def _eval_node(n):\n",
        "    if isinstance(n, ast.Num): return n.n\n",
        "    if isinstance(n, ast.UnaryOp) and type(n.op) in OPS: return OPS[type(n.op)](_eval_node(n.operand))\n",
        "    if isinstance(n, ast.BinOp) and type(n.op) in OPS: return OPS[type(n.op)](_eval_node(n.left), _eval_node(n.right))\n",
        "    raise ValueError(\"Unsafe expression\")\n",
        "def calc(expr: str):\n",
        "    node = ast.parse(expr, mode='eval').body\n",
        "    return _eval_node(node)\n",
        "class FoldingMemory:\n",
        "    def __init__(self, max_chars:int=800):\n",
        "        self.active=[]; self.folds=[]; self.max_chars=max_chars\n",
        "    def add(self,text:str):\n",
        "        self.active.append(text.strip())\n",
        "        while len(self.active_text())>self.max_chars and len(self.active)>1:\n",
        "            popped=self.active.pop(0)\n",
        "            fold=f\"- Folded: {popped[:120]}...\"\n",
        "            self.folds.append(fold)\n",
        "    def fold_in(self,summary:str): self.folds.append(summary.strip())\n",
        "    def active_text(self)->str: return \"\\n\".join(self.active)\n",
        "    def folded_text(self)->str: return \"\\n\".join(self.folds)\n",
        "    def snapshot(self)->Dict: return {\"active_chars\":len(self.active_text()),\"n_folds\":len(self.folds)}"
      ],
      "metadata": {
        "id": "YMrg5FjUwnrx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SUBTASK_DECOMP_PROMPT=\"\"\"You are an expert planner. Decompose the task below into 2-4 crisp subtasks.\n",
        "Return each subtask as a bullet starting with '- ' in priority order.\n",
        "Task: \"{task}\" \"\"\"\n",
        "SUBTASK_SOLVER_PROMPT=\"\"\"You are a precise problem solver with minimal steps.\n",
        "If a calculation is needed, write one line 'CALC(expr)'.\n",
        "Otherwise write 'ANSWER: <final>'.\n",
        "Think briefly; avoid chit-chat.\n",
        "\n",
        "Task: {task}\n",
        "Subtask: {subtask}\n",
        "Notes (folded context):\n",
        "{notes}\n",
        "\n",
        "Now respond with either CALC(...) or ANSWER: ...\"\"\"\n",
        "SUBTASK_SUMMARY_PROMPT=\"\"\"Summarize the subtask outcome in <=3 bullets, total <=50 tokens.\n",
        "Subtask: {name}\n",
        "Steps:\n",
        "{trace}\n",
        "Final: {final}\n",
        "Return only bullets starting with '- '.\"\"\"\n",
        "FINAL_SYNTH_PROMPT=\"\"\"You are a senior agent. Synthesize a final, coherent solution using ONLY:\n",
        "- The original task\n",
        "- Folded summaries (below)\n",
        "Avoid repeating steps. Be concise and actionable.\n",
        "\n",
        "Task: {task}\n",
        "Folded summaries:\n",
        "{folds}\n",
        "\n",
        "Final answer:\"\"\"\n",
        "def parse_bullets(text:str)->List[str]:\n",
        "    return [ln[2:].strip() for ln in text.splitlines() if ln.strip().startswith(\"- \")]"
      ],
      "metadata": {
        "id": "082OEce2wqSL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_subtask(task:str, subtask:str, memory:FoldingMemory, max_tool_iters:int=3)->Tuple[str,str,List[str]]:\n",
        "    notes=(memory.folded_text() or \"(none)\")\n",
        "    trace=[]; final=\"\"\n",
        "    for _ in range(max_tool_iters):\n",
        "        prompt=SUBTASK_SOLVER_PROMPT.format(task=task,subtask=subtask,notes=notes)\n",
        "        out=llm_gen(prompt,max_new_tokens=96); trace.append(out)\n",
        "        m=re.search(r\"CALC\\((.+?)\\)\",out)\n",
        "        if m:\n",
        "            try:\n",
        "                val=calc(m.group(1))\n",
        "                trace.append(f\"TOOL:CALC -> {val}\")\n",
        "                out2=llm_gen(prompt+f\"\\nTool result: {val}\\nNow produce 'ANSWER: ...' only.\",max_new_tokens=64)\n",
        "                trace.append(out2)\n",
        "                if out2.strip().startswith(\"ANSWER:\"):\n",
        "                    final=out2.split(\"ANSWER:\",1)[1].strip(); break\n",
        "            except Exception as e:\n",
        "                trace.append(f\"TOOL:CALC ERROR -> {e}\")\n",
        "        if out.strip().startswith(\"ANSWER:\"):\n",
        "            final=out.split(\"ANSWER:\",1)[1].strip(); break\n",
        "    if not final:\n",
        "        final=\"No definitive answer; partial reasoning:\\n\"+\"\\n\".join(trace[-2:])\n",
        "    summ=llm_gen(SUBTASK_SUMMARY_PROMPT.format(name=subtask,trace=\"\\n\".join(trace),final=final),max_new_tokens=80)\n",
        "    summary_bullets=\"\\n\".join(parse_bullets(summ)[:3]) or f\"- {subtask}: {final[:60]}...\"\n",
        "    return final, summary_bullets, trace\n",
        "class ContextFoldingAgent:\n",
        "    def __init__(self,max_active_chars:int=800):\n",
        "        self.memory=FoldingMemory(max_chars=max_active_chars)\n",
        "        self.metrics={\"subtasks\":0,\"tool_calls\":0,\"chars_saved_est\":0}\n",
        "    def decompose(self,task:str)->List[str]:\n",
        "        plan=llm_gen(SUBTASK_DECOMP_PROMPT.format(task=task),max_new_tokens=96)\n",
        "        subs=parse_bullets(plan)\n",
        "        return subs[:4] if subs else [\"Main solution\"]\n",
        "    def run(self,task:str)->Dict:\n",
        "        t0=time.time()\n",
        "        self.memory.add(f\"TASK: {task}\")\n",
        "        subtasks=self.decompose(task)\n",
        "        self.metrics[\"subtasks\"]=len(subtasks)\n",
        "        folded=[]\n",
        "        for st in subtasks:\n",
        "            self.memory.add(f\"SUBTASK: {st}\")\n",
        "            final,fold_summary,trace=run_subtask(task,st,self.memory)\n",
        "            self.memory.fold_in(fold_summary)\n",
        "            folded.append(f\"- {st}: {final}\")\n",
        "            self.memory.add(f\"SUBTASK_DONE: {st}\")\n",
        "        final=llm_gen(FINAL_SYNTH_PROMPT.format(task=task,folds=self.memory.folded_text()),max_new_tokens=200)\n",
        "        t1=time.time()\n",
        "        return {\"task\":task,\"final\":final.strip(),\"folded_summaries\":self.memory.folded_text(),\n",
        "                \"active_context_chars\":len(self.memory.active_text()),\n",
        "                \"subtask_finals\":folded,\"runtime_sec\":round(t1-t0,2)}"
      ],
      "metadata": {
        "id": "pcTrP-5zwsXc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEMO_TASKS=[\n",
        "    \"Plan a 3-day study schedule for ML with daily workouts and simple meals; include time blocks.\",\n",
        "    \"Compute a small project budget with 3 items (laptop 799.99, course 149.5, snacks 23.75), add 8% tax and 5% buffer, and present a one-paragraph recommendation.\"\n",
        "]\n",
        "def pretty(d): return json.dumps(d, indent=2, ensure_ascii=False)\n",
        "if __name__==\"__main__\":\n",
        "    agent=ContextFoldingAgent(max_active_chars=700)\n",
        "    for i,task in enumerate(DEMO_TASKS,1):\n",
        "        print(\"=\"*70)\n",
        "        print(f\"DEMO #{i}: {task}\")\n",
        "        res=agent.run(task)\n",
        "        print(\"\\n--- Folded Summaries ---\\n\"+(res[\"folded_summaries\"] or \"(none)\"))\n",
        "        print(\"\\n--- Final Answer ---\\n\"+res[\"final\"])\n",
        "        print(\"\\n--- Diagnostics ---\")\n",
        "        diag={k:res[k] for k in [\"active_context_chars\",\"runtime_sec\"]}\n",
        "        diag[\"n_subtasks\"]=len(agent.decompose(task))\n",
        "        print(pretty(diag))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ty_CUdKTwuZh",
        "outputId": "5aa7008d-3bbc-462e-bcd5-87208f445bd5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "DEMO #1: Plan a 3-day study schedule for ML with daily workouts and simple meals; include time blocks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-194531414.py:4: DeprecationWarning: ast.Num is deprecated and will be removed in Python 3.14; use ast.Constant instead\n",
            "  if isinstance(n, ast.Num): return n.n\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Folded Summaries ---\n",
            "- Tasks: Plan a 3-day study schedule for ML with daily workouts and simple meals. Tasks: Plan a 3-day study schedule for ML with daily workouts and simple meals. Tasks: Plan a 3-day study schedule for ML with daily workouts and simple meals. Tasks: Plan a 3-day study schedule for ML with daily workouts and simple meals. Tasks: Plan a 3-day study schedule: No definitive answer; partial reasoning:\n",
            "CALC(...)\n",
            "TOOL:CALC...\n",
            "- Folded: TASK: Plan a 3-day study schedule for ML with daily workouts and simple meals; include time blocks....\n",
            "- Folded: SUBTASK: Tasks: Plan a 3-day study schedule for ML with daily workouts and simple meals. Tasks: Plan a 3-day study sched...\n",
            "\n",
            "--- Final Answer ---\n",
            "Folded summaries (below) Avoid repeating steps. Be concise and actionable. Task: Plan a 3-day study schedule for ML with daily workouts and simple meals. Tasks: Plan a 3-day study schedule for ML with daily workouts and simple meals. Tasks: Plan a 3-day study schedule for ML with daily workouts and simple meals. Tasks: Plan a 3-day study schedule for ML with daily workouts and simple meals. Tasks: Plan a 3-day study schedule for ML with daily workouts and simple meals. Tasks: Plan a 3-day study schedule for ML with daily workouts and simple meals. Tasks: Plan a 3-day study schedule for ML with daily workouts and simple meals. Tasks: Plan a 3-day study schedule for ML with daily workouts and simple meals. Tasks: Plan a 3-day study schedule for\n",
            "\n",
            "--- Diagnostics ---\n",
            "{\n",
            "  \"active_context_chars\": 368,\n",
            "  \"runtime_sec\": 24.1,\n",
            "  \"n_subtasks\": 1\n",
            "}\n",
            "======================================================================\n",
            "DEMO #2: Compute a small project budget with 3 items (laptop 799.99, course 149.5, snacks 23.75), add 8% tax and 5% buffer, and present a one-paragraph recommendation.\n",
            "\n",
            "--- Folded Summaries ---\n",
            "- Tasks: Plan a 3-day study schedule for ML with daily workouts and simple meals. Tasks: Plan a 3-day study schedule for ML with daily workouts and simple meals. Tasks: Plan a 3-day study schedule for ML with daily workouts and simple meals. Tasks: Plan a 3-day study schedule for ML with daily workouts and simple meals. Tasks: Plan a 3-day study schedule: No definitive answer; partial reasoning:\n",
            "CALC(...)\n",
            "TOOL:CALC...\n",
            "- Folded: TASK: Plan a 3-day study schedule for ML with daily workouts and simple meals; include time blocks....\n",
            "- Folded: SUBTASK: Tasks: Plan a 3-day study schedule for ML with daily workouts and simple meals. Tasks: Plan a 3-day study sched...\n",
            "- Main solution: No definitive answer; partial reasoning:\n",
            "CALC(...)\n",
            "TOOL:CALC...\n",
            "\n",
            "--- Final Answer ---\n",
            "No definitive answer; partial reasoning: CALC(...) TOOL:CALC...\n",
            "\n",
            "--- Diagnostics ---\n",
            "{\n",
            "  \"active_context_chars\": 584,\n",
            "  \"runtime_sec\": 10.34,\n",
            "  \"n_subtasks\": 1\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}